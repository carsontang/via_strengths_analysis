{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import networkx as nx\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy\n",
    "\n",
    "from sklearn.cluster import SpectralClustering\n",
    "\n",
    "from constants import (\n",
    "    BAT_SIGNAL_FILE,\n",
    "    BAT_SIGNAL_AND_STEPHAN_FILE,\n",
    "    ALL_FILE,\n",
    ")\n",
    "from util import (\n",
    "    cognitive_dissonance_score,\n",
    "    Strength,\n",
    "    ONEOFFS_TO_TOKEN,\n",
    "    TOKEN_TO_STRENGTH,\n",
    ")\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n"
     ]
    }
   ],
   "source": [
    "def map_to_strength(strength_str):\n",
    "    lowercase = strength_str.lower()\n",
    "    if lowercase in ONEOFFS_TO_TOKEN:\n",
    "        token = ONEOFFS_TO_TOKEN[lowercase]\n",
    "    else:\n",
    "        token = lowercase\n",
    "    \n",
    "    return TOKEN_TO_STRENGTH[token]\n",
    "    \n",
    "def preprocess(strengths):\n",
    "    return [map_to_strength(strength_str.strip()) for strength_str in strengths]\n",
    "\n",
    "with open(BAT_SIGNAL_FILE) as csvfile:\n",
    "    reader = csv.reader(csvfile)\n",
    "    user_strengths = {}\n",
    "    for row in reader:\n",
    "        if len(row) != 26:\n",
    "            print(\"{} has issue\".format(row[0]))\n",
    "        name = row[0]\n",
    "        evaluator = row[1].lower().strip()\n",
    "        strengths_in_order = row[2:]\n",
    "        strengths = preprocess(strengths_in_order)\n",
    "        \n",
    "        if evaluator == \"self\":\n",
    "            user_strengths[name] = strengths\n",
    "print(\"Done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "users = list(user_strengths.keys())\n",
    "\n",
    "d = {}\n",
    "index = {}\n",
    "users.sort() # Needed so that we can create a diagonal matrix\n",
    "for i, user in enumerate(users):\n",
    "    d[user] = [0 for j in range(len(users))]\n",
    "    index[i] = user\n",
    "\n",
    "df = pd.DataFrame(d, dtype=np.float64)\n",
    "df = df.rename(index=index)\n",
    "\n",
    "for user in users:\n",
    "    for other_user in users:\n",
    "        top3 = set(user_strengths[user][:3])\n",
    "        other_top3 = set(user_strengths[other_user][:3])\n",
    "        shared_top3 = (top3 & other_top3)\n",
    "        if shared_top3:\n",
    "            df[user][other_user] = 1\n",
    "            df[other_user][user] = 1\n",
    "        else:\n",
    "            df[user][other_user] = 0\n",
    "            df[other_user][user] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "G = nx.Graph()\n",
    "users = list(user_strengths.keys())\n",
    "node_sizes = []\n",
    "for name in users:\n",
    "#     first, last = name.split(' ')\n",
    "#     G.add_node(first)\n",
    "    G.add_node(name)\n",
    "    node_sizes.append(1200)\n",
    "#     node_colors.append([\"blue\", \"green\", \"red\"][random.randint(0,2)])\n",
    "#     node_sizes.append(random.randint(1, 10)*150)\n",
    "\n",
    "for i, user in enumerate(users):\n",
    "    for j, other_user in enumerate(users[i+1:]):\n",
    "        top3 = set(user_strengths[user][:3])\n",
    "        other_top3 = set(user_strengths[other_user][:3])\n",
    "        shared_top3 = (top3 & other_top3)\n",
    "        if shared_top3:\n",
    "            G.add_edge(user, other_user)\n",
    "\n",
    "adj_sizes = []\n",
    "for i, n in enumerate(G.nodes()):\n",
    "    adj_list_size = len(G.adj[n])\n",
    "    node_sizes[i] *= adj_list_size\n",
    "    adj_sizes.append(adj_list_size)\n",
    "\n",
    "adj_sizes = np.array(adj_sizes)\n",
    "\n",
    "mean = adj_sizes.mean()\n",
    "std = adj_sizes.std()\n",
    "\n",
    "lower_band = mean - std\n",
    "upper_band = mean + std\n",
    "\n",
    "node_colors = []\n",
    "for i, n in enumerate(G.nodes()):\n",
    "    size = adj_sizes[i]\n",
    "    if size < lower_band:\n",
    "        node_colors.append(\"lightblue\")\n",
    "    elif size > upper_band:\n",
    "        node_colors.append(\"lime\")\n",
    "    else:\n",
    "        node_colors.append(\"lightgreen\")\n",
    "\n",
    "def create_user_vec(single_user_strengths):\n",
    "    user_vec = np.empty(24)\n",
    "    for i,strength in enumerate(single_user_strengths):\n",
    "        user_vec[strength.value - 1] = i\n",
    "    return user_vec\n",
    "\n",
    "users = list(user_strengths.keys())\n",
    "\n",
    "d = {}\n",
    "index = {}\n",
    "users.sort() # Needed so that we can create a diagonal matrix\n",
    "for i, user in enumerate(users):\n",
    "    d[user] = [0 for j in range(len(users))]\n",
    "    index[i] = user\n",
    "\n",
    "df = pd.DataFrame(d, dtype=np.float64)\n",
    "df = df.rename(index=index)\n",
    "\n",
    "for i, user in enumerate(users):\n",
    "    for j, other_user in enumerate(users):\n",
    "        if user == other_user:\n",
    "            df[user][other_user] = 0\n",
    "            continue\n",
    "        user_vec = create_user_vec(user_strengths[user])\n",
    "        other_user_vec = create_user_vec(user_strengths[other_user])\n",
    "        corrmatrix = np.corrcoef(user_vec, other_user_vec)\n",
    "        coefficient = corrmatrix[0][1]\n",
    "        df[user][other_user] = coefficient\n",
    "# df\n",
    "\n",
    "edge_colors = []\n",
    "edge_widths = []\n",
    "for i, edge in enumerate(G.edges()):\n",
    "    u1, u2 = edge\n",
    "    coefficient = df[u1][u2]\n",
    "    random_color = [\"turquoise\", \"teal\", \"navy\"]\n",
    "    if coefficient < 0:\n",
    "        edge_colors.append(\"salmon\")\n",
    "        edge_widths.append(1)\n",
    "    elif coefficient > 0.5:\n",
    "        edge_colors.append(\"navy\")\n",
    "        edge_widths.append(4)\n",
    "    elif coefficient > 0.25:\n",
    "        edge_colors.append(\"teal\")\n",
    "        edge_widths.append(2)\n",
    "    else:\n",
    "        edge_colors.append(\"turquoise\")\n",
    "        edge_widths.append(1)\n",
    "\n",
    "# pos = nx.circular_layout(G)\n",
    "# nx.draw(G, pos, with_labels=False, node_color=node_colors, node_size=node_sizes, edge_color=edge_colors, width=edge_widths, font_weight='bold')\n",
    "# # nx.draw(G, pos, with_labels=False, node_size=node_sizes, font_weight='bold')\n",
    "# # for p in pos:  # raise text positions\n",
    "# #     pos[p][1] += 0.08\n",
    "# nx.draw_networkx_labels(G, pos, with_labels=True, font_color='black', node_size=node_sizes)\n",
    "# plt.savefig('graph.png', figsize=(200,200))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "strength_to_top3_users = defaultdict(list)\n",
    "\n",
    "for user in user_strengths:\n",
    "    strengths = user_strengths[user]\n",
    "    top3_strengths = strengths[:3]\n",
    "    for strength in top3_strengths:\n",
    "        strength_to_top3_users[strength.name].append(user)\n",
    "\n",
    "with open(\"top3_result.txt\", \"w\") as top3_file:\n",
    "    for strength in strength_to_top3_users:\n",
    "        num_users_with_strength = len(strength_to_top3_users[strength])\n",
    "        userlist_str = \", \".join(strength_to_top3_users[strength])\n",
    "        top3_file.write(\"(%d) %+22s: %s\\n\" % (num_users_with_strength, strength, userlist_str))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "strength_to_bot3_users = defaultdict(list)\n",
    "\n",
    "for user in user_strengths:\n",
    "    strengths = user_strengths[user]\n",
    "    bot3_strengths = strengths[-3:]\n",
    "    for strength in bot3_strengths:\n",
    "        strength_to_bot3_users[strength.name].append(user)\n",
    "\n",
    "with open(\"bot3_result.txt\", \"w\") as bot3_file:\n",
    "    for strength in strength_to_bot3_users:\n",
    "        num_users_with_strength = len(strength_to_bot3_users[strength])\n",
    "        userlist_str = \", \".join(strength_to_bot3_users[strength])\n",
    "        bot3_file.write(\"(%d) %+22s: %s\\n\" % (num_users_with_strength, strength, userlist_str))\n",
    "print('done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def create_user_vec(single_user_strengths):\n",
    "    user_vec = np.empty(24)\n",
    "    for i,strength in enumerate(single_user_strengths):\n",
    "        user_vec[strength.value - 1] = i\n",
    "    return user_vec\n",
    "\n",
    "users = list(user_strengths.keys())\n",
    "\n",
    "d = {}\n",
    "index = {}\n",
    "users.sort() # Needed so that we can create a diagonal matrix\n",
    "for i, user in enumerate(users):\n",
    "    d[user] = [0 for j in range(len(users))]\n",
    "    index[i] = user\n",
    "\n",
    "df = pd.DataFrame(d, dtype=np.float64)\n",
    "df = df.rename(index=index)\n",
    "\n",
    "for i, user in enumerate(users):\n",
    "    for j, other_user in enumerate(users):\n",
    "        if user == other_user:\n",
    "            df[user][other_user] = 0\n",
    "            continue\n",
    "        user_vec = create_user_vec(user_strengths[user])\n",
    "        other_user_vec = create_user_vec(user_strengths[other_user])\n",
    "        corrmatrix = np.corrcoef(user_vec, other_user_vec)\n",
    "        coefficient = corrmatrix[0][1]\n",
    "        df[user][other_user] = coefficient\n",
    "# for user in users:\n",
    "#     print(\"%20s ---> %-20s\" % (user, df[user].idxmax()))\n",
    "\n",
    "# plt.rcParams[\"figure.figsize\"] = [20,20]\n",
    "# users = list(user_strengths.keys())\n",
    "# DG = nx.DiGraph()\n",
    "# # DG.add_weighted_edges_from([ (\"Angelina Huang\", \"Allen Wu\", 0.249565), (\"Angelina Huang\", \"Anh Tran\", 0.034783)])\n",
    "# DG.add_weighted_edges_from([ (\"Angelina Huang\", \"Allen Wu\", 1), (\"Angelina Huang\", \"Anh Tran\", 0.034783)])\n",
    "# pos = nx.circular_layout(DG)\n",
    "# nx.draw(DG, pos, with_labels=False, node_size=node_sizes, font_weight='bold')\n",
    "# df[\"Angelina Huang\"]\n",
    "\n",
    "# DG.add_weighted_edges_from([(1, 2, 0.5), (3, 1, 0.75)])\n",
    "# pos = nx.circular_layout(DG)\n",
    "# nx.draw(DG, pos, with_labels=False, node_size=node_sizes, font_weight='bold')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.10438157954858163\n",
      "4.279596331234476\n"
     ]
    }
   ],
   "source": [
    "firstrow = None\n",
    "secondrow = None\n",
    "thirdrow = None\n",
    "fourthrow = None\n",
    "with open('carson.csv') as csvfile:\n",
    "    reader = csv.reader(csvfile)\n",
    "    for row in reader:\n",
    "        if firstrow is None:\n",
    "            firstrow = row\n",
    "        elif secondrow is None:\n",
    "            secondrow = row\n",
    "        elif thirdrow is None:\n",
    "            thirdrow = row\n",
    "        elif fourthrow is None:\n",
    "            fourthrow = row\n",
    "    \n",
    "\n",
    "self_perception_scores = np.empty(24)\n",
    "for i, token in enumerate(firstrow[2:]):\n",
    "    strength_str = token.strip()\n",
    "    self_perception_scores[TOKEN_TO_STRENGTH[strength_str].value - 1] = i\n",
    "\n",
    "external_perception_scores1 = np.empty(24)\n",
    "for i, token in enumerate(secondrow[2:]):\n",
    "    strength_str = token.strip()\n",
    "    external_perception_scores1[TOKEN_TO_STRENGTH[strength_str].value - 1] = i\n",
    "\n",
    "external_perception_scores2 = np.empty(24)\n",
    "for i, token in enumerate(thirdrow[2:]):\n",
    "    strength_str = token.strip()\n",
    "    external_perception_scores2[TOKEN_TO_STRENGTH[strength_str].value - 1] = i\n",
    "\n",
    "external_perception_scores3 = np.empty(24)\n",
    "for i, token in enumerate(fourthrow[2:]):\n",
    "    strength_str = token.strip()\n",
    "    external_perception_scores3[TOKEN_TO_STRENGTH[strength_str].value - 1] = i\n",
    "\n",
    "external_perception_score = (external_perception_scores1 + external_perception_scores2 + external_perception_scores3)/3.0\n",
    "# print(self_perception_scores)\n",
    "# print(external_perception_scores1)\n",
    "# print(external_perception_scores2)\n",
    "# print(external_perception_scores3)\n",
    "\n",
    "cog_diss = cognitive_dissonance_score(external_perception_score, self_perception_scores)\n",
    "s = scipy.spatial.distance.cosine(external_perception_score, self_perception_scores)\n",
    "print(s)\n",
    "print(cog_diss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.08117483811285842\n",
      "4.279596331234476\n"
     ]
    }
   ],
   "source": [
    "firstrow = None\n",
    "secondrow = None\n",
    "thirdrow = None\n",
    "fourthrow = None\n",
    "with open('jessica.csv') as csvfile:\n",
    "    reader = csv.reader(csvfile)\n",
    "    for row in reader:\n",
    "        if firstrow is None:\n",
    "            firstrow = row\n",
    "        elif secondrow is None:\n",
    "            secondrow = row\n",
    "        elif thirdrow is None:\n",
    "            thirdrow = row\n",
    "        elif fourthrow is None:\n",
    "            fourthrow = row\n",
    "    \n",
    "\n",
    "self_perception_scores = np.empty(24)\n",
    "for i, token in enumerate(firstrow[2:]):\n",
    "    strength_str = token.strip()\n",
    "    self_perception_scores[TOKEN_TO_STRENGTH[strength_str].value - 1] = i\n",
    "\n",
    "external_perception_scores1 = np.empty(24)\n",
    "for i, token in enumerate(secondrow[2:]):\n",
    "    strength_str = token.strip()\n",
    "    external_perception_scores1[TOKEN_TO_STRENGTH[strength_str].value - 1] = i\n",
    "\n",
    "s = scipy.spatial.distance.cosine(external_perception_scores1, self_perception_scores)\n",
    "print(s)\n",
    "print(cog_diss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1302035152636447\n",
      "4.279596331234476\n"
     ]
    }
   ],
   "source": [
    "firstrow = None\n",
    "secondrow = None\n",
    "thirdrow = None\n",
    "fourthrow = None\n",
    "with open('anh.csv') as csvfile:\n",
    "    reader = csv.reader(csvfile)\n",
    "    for row in reader:\n",
    "        if firstrow is None:\n",
    "            firstrow = row\n",
    "        elif secondrow is None:\n",
    "            secondrow = row\n",
    "        elif thirdrow is None:\n",
    "            thirdrow = row\n",
    "        elif fourthrow is None:\n",
    "            fourthrow = row\n",
    "    \n",
    "\n",
    "self_perception_scores = np.empty(24)\n",
    "for i, token in enumerate(firstrow[2:]):\n",
    "    strength_str = token.strip()\n",
    "    self_perception_scores[TOKEN_TO_STRENGTH[strength_str].value - 1] = i\n",
    "\n",
    "external_perception_scores1 = np.empty(24)\n",
    "for i, token in enumerate(secondrow[2:]):\n",
    "    strength_str = token.strip()\n",
    "    external_perception_scores1[TOKEN_TO_STRENGTH[strength_str].value - 1] = i\n",
    "\n",
    "s = scipy.spatial.distance.cosine(self_perception_scores, external_perception_scores1)\n",
    "\n",
    "s = scipy.spatial.distance.cosine(external_perception_scores1, self_perception_scores)\n",
    "print(s)\n",
    "print(cog_diss)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:via_strengths_analysis]",
   "language": "python",
   "name": "conda-env-via_strengths_analysis-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
